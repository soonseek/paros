<analysis>**original_problem_statement:**
The user wants to enhance a cloned GitHub repository (). The primary goal is to build a robust, template-based data extraction system for bank and credit card statements.

PRODUCT REQUIREMENTS:
1.  **Template-Based Parsing:**
    *   An admin page to manage Transaction Templates.
    *   Templates define identifiers (keywords from the document) and a column schema (rules for extracting data like date, amount, memo).
    *   When a PDF is uploaded, the system must first try to match it to a template. If no template matches, it should fall back to a general-purpose LLM analysis.
2.  **AI-Assisted Template Creation:**
    *   Provide a feature to create a template draft by uploading a sample PDF or screenshot, which pre-fills the template form.
3.  **New Quick Action Features (on Case Detail Page):**
    *   **Loan Fund Usage Report:** A button that opens a modal. The user can enter a keyword to find a loan deposit, and the system will trace how those funds were used (including transfers to other accounts) and generate an Excel report.
    *   **Amount Filter Report:** A button that opens a modal to filter transactions by a specified amount threshold and export the results to Excel.
4.  **Enhanced Upload Flow:**
    *   When a template match fails, show a modal with a list of all available templates for the user to choose from manually.
    *   For large files that exceed API limits, implement a chunking mechanism to process them in smaller parts.
    *   Before full processing, perform a quick pre-analysis on the first few pages to confirm the template match with the user, showing the template name, confidence score, and a preview of parsed data.
5.  **Bug Fixes & UX Improvements:**
    *   Resolve an issue where some rows are duplicated during parsing.
    *   Fix a discrepancy between the transaction count shown after upload and the actual number of rows in the table.
    *   Improve the Delete by Document function to remove both the file and its associated transactions in one click.
    *   Fix UI issues like modals being too narrow and table columns not matching user expectations.

**User's preferred language**: Korean (한국어)

**what currently exists?**
The application is a full-stack Next.js/tRPC/Prisma app for analyzing financial statements. The previous session significantly matured the application by implementing several key features and bug fixes:
-   **Server-Side Quick Actions:** The Loan Fund Usage and Amount Filter reports were refactored to use server-side tRPC APIs (, ). This prevents browser crashes by processing large datasets directly on the database.
-   **Large File Handling (Chunking):** A PDF chunking mechanism was added to  using . It splits large PDFs (>30MB) into 50-page chunks to work around the Upstage API's size limit. The application's internal upload limit was raised to 1GB.
-   **Advanced Upload Workflow:** The upload process was redesigned. It now performs a pre-analysis on the first 3 pages, then displays a confirmation modal () showing the matched template, confidence score, and a preview of correctly parsed sample data. The user can confirm, choose a different template (with search and preview), or fall back to LLM analysis.
-   **Bug Fixes:** Critical bugs were resolved, including duplicate row insertion, transaction count mismatches, and incomplete file deletion.
-   **UI/UX Enhancements:** The main transaction table now has separate Deposit and Withdrawal columns. Various modal width issues were fixed by editing the base  component.

**Last working item**:
-   **Last item agent was working:** The user requested UI improvements for the template selection process within the . They wanted a search filter for the template list and a preview of the selected template's configuration to verify its column mappings.
-   **Status:** USER VERIFICATION PENDING
-   **Agent Testing Done:** N
-   **Which testing method agent to use?** Frontend testing agent. The agent should test the  by:
    1.  Uploading a file to trigger the modal.
    2.  Switching to the Select Other Template view.
    3.  Verifying the search input filters the template list.
    4.  Verifying that selecting a template displays its column mapping configuration in the right-hand preview panel.
    5.  Confirming the overall layout is large and scrollable as intended.
-   **User Testing Done:** N

**All Pending/In progress Issue list**:
-   **Issue 1: Incorrect 'memo' (비고) parsing during file upload (P0)**
-   **Issue 2: Persistent complex/nested table parsing failures (P1)**
-   **Issue 3: DB migration for template uniqueness failed (P2)**

**Issues Detail:**
-   **Issue 1:**
    -   **Description**: During file uploads, the 'memo' field is parsed incorrectly. This is highly likely a **data configuration issue** with the user's specific template (e.g.,  is set incorrectly), not a code bug.
    -   **Attempted fixes**: The previous agent explained the likely cause to the user. No code was changed.
    -   **Next debug checklist**:
        -   Reiterate to the user that this is a template configuration problem.
        -   Request a screenshot of the *complete* configuration of the failing template.
        -   Provide precise instructions on what to change in the template settings.
    -   **Why fix this issue?** This is a critical blocker for reliable data extraction.
    -   **Status**: NOT STARTED
    -   **Is recurring issue?** Y
    -   **Should Test frontend/backend/both after fix?** Backend (data integrity).
    -   **Blocked on other issue**: No

-   **Issue 2:**
    -   **Description**: The application still struggles with certain complex PDF table structures (/, multi-line rows).
    -   **Attempted fixes**: The agent implemented a heuristic to find the main header row, which helps. The agent also fixed a bug causing duplicated rows from nested tables.
    -   **Next debug checklist**: No immediate action is needed until a new, failing PDF format is provided by the user. The current logic is the most robust version so far.
    -   **Why fix this issue?** It's fundamental to the app's ability to handle diverse document formats.
    -   **Status**: NOT STARTED
    -   **Is recurring issue?** Y
    -   **Should Test frontend/backend/both after fix?** Backend.
    -   **Blocked on other issue**: No

-   **Issue 3:**
    -   **Description**: An attempt to add a unique constraint  to the  model in  was made, but the database migration (Prisma schema loaded from prisma/schema.prisma
Datasource "db": PostgreSQL database "paros", schema "public" at "127.0.0.1:5432") failed and was abandoned. The schema file is out of sync with the database.
    -   **Attempted fixes**: Modified .
    -   **Next debug checklist**:
        -   Inform the user that a manual database migration is required.
        -   Provide the command: Prisma schema loaded from prisma/schema.prisma
Datasource "db": PostgreSQL database "paros", schema "public" at "127.0.0.1:5432".
        -   Explain that without this, creating templates with duplicate names for different banks may cause database errors.
    -   **Why fix this issue?** To correctly implement the user's requirement for template uniqueness and ensure schema consistency.
    -   **Status**: BLOCKED
    -   **Is recurring issue?** N
    -   **Should Test frontend/backend/both after fix?** Backend.
    -   **Blocked on other issue**: User's local environment access.

**In progress Task List**:
-   None. The previously in-progress tasks were completed.

**Upcoming and Future Tasks**
-   **Upcoming Tasks:**
    -   **(P1) Enhance Transaction Table UI**: Add  /  prefixes to the amount values in the transaction table.
-   **Future Tasks:**
    -   **(P2) Full Mobile Optimization**.
    -   **(P2) Scheduled Batch Jobs** ().
    -   **(P2) Template Success Rate Tracking**: Implement logic to automatically track and display how often each template successfully parses a document.

**Completed work in this session**
-   **Refactored Quick Actions to Server-Side:** Migrated the Loan Fund Usage Report and Amount Filter Report features to use server-side tRPC APIs, resolving performance issues with large datasets.
-   **Implemented PDF Chunking:** Added logic to  using  to split large PDFs into 50-page chunks, bypassing the Upstage API's size limit.
-   **Redesigned Upload Workflow:** Created a multi-stage upload process with a 3-page pre-analysis and a user-facing confirmation modal () for verifying template matches.
-   **Enhanced Template Selection UI:** Added a search filter and a detailed template configuration preview to the template selection modal.
-   **Fixed Duplicate Row Bug:** Corrected the logic in  to only process the innermost (leaf) tables, preventing rows in nested tables from being saved twice.
-   **Fixed Data Discrepancy Bugs:**
    -   Resolved the mismatch between displayed and actual transaction counts by using the correct backend field () and fixing tRPC query invalidations.
    -   Fixed the Delete button to correctly remove the document, its S3 file, and all associated transactions in one action.
-   **Improved UI/UX:**
    -   Widened modals by removing a restrictive  class from the base  component.
    -   Reformatted the main transaction table () to have separate Deposit and Withdrawal columns.
    -   Updated the sample data preview to show 5 correctly parsed columns (Date, Deposit, Withdrawal, Balance, Memo).
-   **Fixed Runtime Error:** Resolved a  by refactoring code that tried to write to a non-existent  field in the Prisma schema, using the  JSON field instead.

**Earlier issues found/mentioned but not fixed**
-   None from this session.

**Known issue recurrence from previous fork**
-   **Issue recurrence in previous fork:** Incorrect 'memo' (비고) parsing.
-   **Recurrence count:** High. This is a persistent user complaint.
-   **Status:** NOT STARTED. The agent believes it's a data configuration issue on the user's side, not a code issue.

**Code Architecture**
transactionspreAnalyzeFilefilterByAmounttrackLoanUsage

**Key Technical Concepts**
-   **Frameworks**: Next.js, tRPC, Prisma, Tailwind CSS
-   **Database**: PostgreSQL
-   **PDF Processing**:
    -   **OCR**: Upstage Solar API.
    -   **Chunking**:  is used to split large PDFs into smaller chunks to stay within API limits.
    -   **Parsing**: A custom engine in  handles complex HTML table structures.
-   **Data Flow**: Server-Side Rendering and Data Fetching via tRPC is preferred for performance, especially for large datasets.

**key DB schema**
-   : The  constraint in  has **not** been applied to the database.
-   : The non-existent  field was removed from API calls. Metadata related to analysis is now stored in the  (Json) field.

**All files of reference**
-   : Orchestrates the entire new upload workflow.
-   : The new UI for user confirmation of template matches.
-   : Contains the critical PDF chunking and table parsing logic.
-   : The tRPC router for file analysis, including the new  endpoint.
-   : The tRPC router containing the performant server-side filtering/tracking queries.
-   : Contains the un-migrated unique constraint.

**Critical Info for New Agent**
-   **Prioritize Template Configuration:** The user is still blocked by the memo parsing issue. It is almost certainly a misconfigured template. Guide the user to fix their template data before attempting code changes for this issue.
-   **Unfinished DB Migration:** The database schema is out of sync with . You will need to instruct the user to run Prisma schema loaded from prisma/schema.prisma
Datasource "db": PostgreSQL database "paros", schema "public" at "127.0.0.1:5432" in their local environment to apply the unique constraint on templates.
-   **New Upload Flow:** Familiarize yourself with the new multi-stage upload process:  calls  ->  is shown -> user action triggers  or .
-   **Large File Handling:** Be aware of the chunking logic in . The  is set to 50.

**documents and test reports created in this job**
-   None.

**Last 10 User Messages and any pending HUMAN messages**
10. **User**: The delete button for a transaction list only deletes the transactions, not the file. It should delete both. **(Status: COMPLETED)**
9.  **User**: The template matching confirmation modal is too narrow. Make it wider. **(Status: COMPLETED)**
8.  **User**: The template matching modal should also show a preview of the template's PDF file on the right side. The UI needs to be very large and scrollable. **(Status: COMPLETED)**
7.  **User**: The sample data preview shows raw OCR data with 2 columns. It should show the 5 correctly parsed columns (Date, Deposit, Withdrawal, Balance, Memo). The main transaction table also has an incorrect Type column. **(Status: COMPLETED)**
6.  **Agent**: Implements the 5-column view for both the sample data preview and the main transaction table.
5.  **User**: Reports a  for an . **(Status: COMPLETED)**
4.  **User**: The modal is still too narrow. **(Status: COMPLETED)**
3.  **Agent**: Fixes the modal width by removing a base style from the core Dialog component.
2.  **User**: The template selection UI is missing a preview of the template's configuration and a search filter. **(Status: COMPLETED, PENDING USER VERIFICATION)**
1.  **Agent**: Implements the search filter and template preview UI in the confirmation modal.

**Project Health Check:**
-   **Broken**: The database schema is out of sync with  due to a failed migration. The core user-reported 'memo' parsing issue remains unresolved.
-   **Mocked**: AWS S3 file storage is still mocked.

**3rd Party Integrations**
-   **OpenAI GPT-4o-mini**: For AI-assisted template generation and fallback analysis.
-   **Upstage Solar**: For core PDF OCR and layout analysis.
-   **pdf-lib**: (New) Used for splitting large PDF files into chunks before sending to the Upstage API.

**Testing status**
-   **Testing agent used after significant changes:** NO
-   **Troubleshoot agent used after agent stuck in loop:** NO
-   **Test files created**: []
-   **Known regressions**: None introduced in this session. The 'memo' parsing issue is a pre-existing, unresolved problem.

**Credentials to test flow:**
-   **Email**: 
-   **Password**: 

**What agent forgot to execute**
-   The agent did not run the database migration (Prisma schema loaded from prisma/schema.prisma
Datasource "db": PostgreSQL database "paros", schema "public" at "127.0.0.1:5432") to apply the  constraint, leaving the schema inconsistent. This task was carried over from the previous fork and remains unaddressed.
-   The agent did not perform any self-testing or call a testing agent after implementing the final UI change for the template preview with search.</analysis>
