# Story 3.3: S3 íŒŒì¼ ì €ì¥ ë° ë©”íƒ€ë°ì´í„° ê´€ë¦¬

**Status:** ready-for-dev
**Epic:** Epic 3 - ê±°ë˜ë‚´ì—­ì„œ ì—…ë¡œë“œ ë° ì „ì²˜ë¦¬
**Story Key:** 3-3-s3-file-storage-metadata
**Created:** 2026-01-09
**Dependencies:** Epic 1 ì™„ë£Œ (ì‚¬ìš©ì ì¸ì¦), Epic 2 ì™„ë£Œ (ì‚¬ê±´ ê´€ë¦¬), Story 3.1 ì™„ë£Œ (íŒŒì¼ ì—…ë¡œë“œ UI), Story 3.2 ì™„ë£Œ (íŒŒì¼ í˜•ì‹ ê²€ì¦)

---

## Story

**As a** ì‹œìŠ¤í…œ,
**I want** ì—…ë¡œë“œëœ íŒŒì¼ì„ S3ì— ì €ì¥í•˜ê³  ë©”íƒ€ë°ì´í„°ë¥¼ DBì— ê¸°ë¡í•´ì„œ,
**So that** íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ì €ì¥í•˜ê³  ì¶”ì í•  ìˆ˜ ìˆë‹¤.

---

## Acceptance Criteria

### AC1: S3 íŒŒì¼ ì—…ë¡œë“œ

**Given** íŒŒì¼ í˜•ì‹ ê²€ì¦ì´ í†µê³¼ëœ íŒŒì¼ì´ ìˆì„ ë•Œ
**When** íŒŒì¼ ì—…ë¡œë“œê°€ ì‹œì‘ë˜ë©´
**Then** íŒŒì¼ì€ ap-northeast-2 ë¦¬ì „ì˜ AWS S3 ë²„í‚·ì— ì—…ë¡œë“œëœë‹¤
**And** íŒŒì¼ì€ ê³ ìœ í•œ íŒŒì¼ëª…(UUID)ìœ¼ë¡œ ì €ì¥ëœë‹¤
**And** ì›ë³¸ íŒŒì¼ëª…ì€ ë©”íƒ€ë°ì´í„°ë¡œ ë³´ì¡´ëœë‹¤

### AC2: Document ë©”íƒ€ë°ì´í„° ìƒì„±

**Given** íŒŒì¼ì´ S3ì— ì—…ë¡œë“œë˜ì—ˆì„ ë•Œ
**When** ì—…ë¡œë“œê°€ ì™„ë£Œë˜ë©´
**Then** Document í…Œì´ë¸”ì— íŒŒì¼ ë©”íƒ€ë°ì´í„°ê°€ ìƒì„±ëœë‹¤
**And** ë©”íƒ€ë°ì´í„°ì—ëŠ” ì›ë³¸ íŒŒì¼ëª…, S3 í‚¤, íŒŒì¼ í¬ê¸°, MIME íƒ€ì…, ì—…ë¡œë“œì¼ì‹œ, ì†Œìœ ì ID, ì—°ê²°ëœ Case IDê°€ í¬í•¨ëœë‹¤

### AC3: ì—…ë¡œë“œ ì‹¤íŒ¨ ì²˜ë¦¬

**Given** íŒŒì¼ ì—…ë¡œë“œ ì¤‘ì— ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ë•Œ
**When** ì—…ë¡œë“œê°€ ì‹¤íŒ¨í•˜ë©´
**Then** "íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”" ì—ëŸ¬ ë©”ì‹œì§€ê°€ í‘œì‹œëœë‹¤
**And** ë¶€ë¶„ì ìœ¼ë¡œ ì—…ë¡œë“œëœ S3 ê°ì²´ëŠ” ì‚­ì œëœë‹¤

### AC4: íŒŒì¼ ì ‘ê·¼ ì œì–´

**Given** ì‚¬ìš©ìê°€ ìì‹ ì˜ íŒŒì¼ì´ ì•„ë‹Œ ë‹¤ë¥¸ ì‚¬ìš©ìì˜ íŒŒì¼ì— ì ‘ê·¼í•˜ë ¤ê³  í•  ë•Œ
**When** S3 URLì„ í†µí•´ ì§ì ‘ ì ‘ê·¼ì„ ì‹œë„í•˜ë©´
**Then** presigned URLì´ ë§Œë£Œë˜ì—ˆê±°ë‚˜ ê¶Œí•œì´ ì—†ì–´ ì ‘ê·¼ì´ ê±°ë¶€ëœë‹¤

**Requirements:** FR-017, NFR-016 (S3 ì§ì ‘ í†µí•©), Architecture (AWS S3 ap-northeast-2)

---

## Developer Context & Guardrails

### ğŸ¯ CRITICAL IMPLEMENTATION REQUIREMENTS

**ğŸš¨ THIS IS THE MOST IMPORTANT SECTION - READ CAREFULLY!**

### Technical Stack & Versions

- **Framework:** Next.js 14+ (Pages Router) - í”„ë¡œì íŠ¸ëŠ” Pages Router ì‚¬ìš©
- **Language:** TypeScript (strict mode)
- **Database:** PostgreSQL with Prisma ORM 7.2.0+
- **API Layer:** tRPC v11
- **State Management:** TanStack Query v5 (React Query)
- **UI Components:** shadcn/ui (Radix UI)
- **File Storage:** AWS S3 (ap-northeast-2 ë¦¬ì „)
- **AWS SDK:** AWS SDK v3 for JavaScript
- **File Upload:** Server-side upload (MVP), í˜„ì¬ Story 3.2ì˜ Base64 ê²€ì¦ í™œìš©

### Architecture Compliance

**1. Prisma Schema - Document Model**

ë¨¼ì € Document ëª¨ë¸ì„ Prisma schemaì— ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤:

```prisma
// prisma/schema.prisma

model Document {
  id          String   @id @default(uuid())
  caseId      String
  originalFileName String
  s3Key       String   @unique // S3 ê°ì²´ í‚¤ (UUID)
  fileSize    Int      // íŒŒì¼ í¬ê¸° (bytes)
  mimeType    String   // MIME íƒ€ì…
  uploadedAt  DateTime @default(now())
  uploaderId  String   // ì—…ë¡œë” ì‚¬ìš©ì ID

  case        Case     @relation(fields: [caseId], references: [id], onDelete: Cascade)
  uploader    User     @relation(fields: [uploaderId], references: [id])

  @@index([caseId])
  @@index([uploaderId])
  @@map("documents")
}
```

**2. S3 Configuration**

```typescript
// src/lib/s3.ts (NEW FILE)

import { S3Client, PutObjectCommand, DeleteObjectCommand } from "@aws-sdk/client-s3";
import { randomUUID } from "crypto";

// S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
const s3Client = new S3Client({
  region: process.env.AWS_REGION || "ap-northeast-2",
  credentials: {
    accessKeyId: process.env.AWS_ACCESS_KEY_ID!,
    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!,
  },
});

export const S3_BUCKET = process.env.S3_BUCKET_NAME || "pharos-bmad-files";

/**
 * S3ì— íŒŒì¼ ì—…ë¡œë“œ
 *
 * @param fileBuffer - íŒŒì¼ ë²„í¼
 * @param fileName - ì›ë³¸ íŒŒì¼ëª…
 * @param mimeType - MIME íƒ€ì…
 * @returns S3 í‚¤ (UUID)
 */
export async function uploadFileToS3(
  fileBuffer: Buffer,
  fileName: string,
  mimeType: string
): Promise<string> {
  // UUID ìƒì„±í•˜ì—¬ ê³ ìœ í•œ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©
  const s3Key = `${randomUUID()}-${fileName}`;

  const command = new PutObjectCommand({
    Bucket: S3_BUCKET,
    Key: s3Key,
    Body: fileBuffer,
    ContentType: mimeType,
    // ì„œë²„ ì¸¡ ì•”í˜¸í™” (AES-256)
    ServerSideEncryption: "AES256",
  });

  try {
    await s3Client.send(command);
    return s3Key;
  } catch (error) {
    console.error("[S3 Upload Error]", error);
    throw new Error("S3 íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨");
  }
}

/**
 * S3ì—ì„œ íŒŒì¼ ì‚­ì œ
 *
 * @param s3Key - S3 ê°ì²´ í‚¤
 */
export async function deleteFileFromS3(s3Key: string): Promise<void> {
  const command = new DeleteObjectCommand({
    Bucket: S3_BUCKET,
    Key: s3Key,
  });

  try {
    await s3Client.send(command);
  } catch (error) {
    console.error("[S3 Delete Error]", error);
    throw new Error("S3 íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨");
  }
}
```

**3. tRPC Router - File Upload Mutation**

Story 3.2ì˜ file ë¼ìš°í„°ë¥¼ í™•ì¥í•˜ì—¬ ì—…ë¡œë“œ ê¸°ëŠ¥ì„ ì¶”ê°€í•©ë‹ˆë‹¤:

```typescript
// src/server/api/routers/file.ts (MODIFY - ADD to existing file.ts)

import { TRPCError } from "@trpc/server";
import { z } from "zod";
import { randomUUID } from "crypto";
import * as XLSX from "xlsx";
import * as pdfParse from "pdf-parse";
import { PutObjectCommand, DeleteObjectCommand } from "@aws-sdk/client-s3";

import { createTRPCRouter, protectedProcedure } from "~/server/api/trpc";
import { FILE_VALIDATION, validateFileSignature } from "~/lib/file-validation";
import { uploadFileToS3, deleteFileFromS3 } from "~/lib/s3";

// S3 í´ë¼ì´ì–¸íŠ¸ëŠ” s3.tsì—ì„œ ê´€ë¦¬

export const fileRouter = createTRPCRouter({
  // ... ê¸°ì¡´ validateFileFormat mutation ìœ ì§€ ...

  /**
   * Upload validated file to S3 and create Document record
   *
   * POST /api/trpc/file.uploadFile
   *
   * Flow:
   * 1. Validate file format (re-use validateFileFormat)
   * 2. Upload to S3 with UUID filename
   * 3. Create Document record in DB
   * 4. Return Document metadata
   *
   * @param caseId - Case ID to link file to
   * @param fileName - Original filename
   * @param fileType - MIME type
   * @param fileSize - File size in bytes
   * @param fileBuffer - Base64-encoded file content
   *
   * @returns Created Document object
   *
   * @throws BAD_REQUEST if validation fails
   * @throws INTERNAL_SERVER_ERROR if S3 upload or DB create fails
   */
  uploadFile: protectedProcedure
    .input(
      z.object({
        caseId: z.string().min(1, "ì‚¬ê±´ IDëŠ” í•„ìˆ˜ í•­ëª©ì…ë‹ˆë‹¤"),
        fileName: z.string().min(1, "íŒŒì¼ëª…ì€ í•„ìˆ˜ í•­ëª©ì…ë‹ˆë‹¤"),
        fileType: z.string().min(1, "íŒŒì¼ íƒ€ì…ì€ í•„ìˆ˜ í•­ëª©ì…ë‹ˆë‹¤"),
        fileSize: z.number().min(0, "íŒŒì¼ í¬ê¸°ëŠ” 0 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤"),
        fileBuffer: z.string().min(1, "íŒŒì¼ ë‚´ìš©ì€ í•„ìˆ˜ í•­ëª©ì…ë‹ˆë‹¤"),
      })
    )
    .mutation(async ({ ctx, input }) => {
      const { caseId, fileName, fileType, fileSize, fileBuffer } = input;
      const userId = ctx.userId;

      // Step 1: Validate file format (re-use Story 3.2 validation)
      let validatedFileType: string | undefined;
      try {
        // File size validation
        if (fileSize > FILE_VALIDATION.MAX_FILE_SIZE_ENCODED_BYTES) {
          throw new TRPCError({
            code: "BAD_REQUEST",
            message: `íŒŒì¼ í¬ê¸°ëŠ” ${FILE_VALIDATION.MAX_FILE_SIZE_MB}MB ì´í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤`,
          });
        }

        // MIME type validation
        if (
          !FILE_VALIDATION.ALLOWED_MIME_TYPES.includes(
            fileType as (typeof FILE_VALIDATION.ALLOWED_MIME_TYPES)[number]
          )
        ) {
          throw new TRPCError({
            code: "BAD_REQUEST",
            message: "ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤",
          });
        }

        // File structure parsing
        const buffer = Buffer.from(fileBuffer, "base64");
        const fileExtension = fileName.slice(fileName.lastIndexOf("."));

        if (!validateFileSignature(buffer, fileExtension)) {
          throw new TRPCError({
            code: "BAD_REQUEST",
            message: "íŒŒì¼ í˜•ì‹ì´ í™•ì¥ìì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤",
          });
        }

        // Detect file type for metadata
        if (fileExtension.endsWith(".xlsx") || fileExtension.endsWith(".xls")) {
          validatedFileType = "ì—‘ì…€ íŒŒì¼";
        } else if (fileExtension.endsWith(".csv")) {
          validatedFileType = "CSV íŒŒì¼";
        } else if (fileExtension.endsWith(".pdf")) {
          validatedFileType = "PDF íŒŒì¼";
        }
      } catch (error) {
        if (error instanceof TRPCError) {
          throw error;
        }
        throw new TRPCError({
          code: "BAD_REQUEST",
          message: "íŒŒì¼ í˜•ì‹ ê²€ì¦ ì‹¤íŒ¨",
        });
      }

      // Step 2: Upload to S3
      let s3Key: string;
      try {
        const buffer = Buffer.from(fileBuffer, "base64");
        s3Key = await uploadFileToS3(buffer, fileName, fileType);
      } catch (error) {
        console.error("[S3 Upload Error]", error);
        throw new TRPCError({
          code: "INTERNAL_SERVER_ERROR",
          message: "íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”",
        });
      }

      // Step 3: Create Document record
      try {
        const document = await ctx.db.document.create({
          data: {
            caseId,
            originalFileName: fileName,
            s3Key,
            fileSize,
            mimeType: fileType,
            uploaderId: userId,
          },
        });

        return {
          success: true,
          document,
          message: `${validatedFileType || "íŒŒì¼"} ì—…ë¡œë“œ ì™„ë£Œ`,
        };
      } catch (error) {
        // Rollback: Delete S3 object if DB create fails
        console.error("[DB Create Error]", error);
        try {
          await deleteFileFromS3(s3Key);
        } catch (deleteError) {
          console.error("[S3 Rollback Error]", deleteError);
        }

        throw new TRPCError({
          code: "INTERNAL_SERVER_ERROR",
          message: "íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨",
        });
      }
    }),
});
```

**4. Frontend Integration - Modify FileUploadZone**

Story 3.2ì˜ FileUploadZoneì„ ìˆ˜ì •í•˜ì—¬ ì—…ë¡œë“œ ê¸°ëŠ¥ì„ ì—°ê²°í•©ë‹ˆë‹¤:

```typescript
// src/components/upload-zone.tsx (MODIFY)

import { useCallback, useState, useRef } from "react";
import { useDropzone, type FileRejection } from "react-dropzone";
import { Button } from "~/components/ui/button";
import { Card } from "~/components/ui/card";
import { Upload, X, AlertCircle } from "lucide-react";
import { toast } from "sonner";
import { api } from "~/utils/api";
import { FILE_VALIDATION } from "~/lib/file-validation";

interface FileUploadProps {
  caseId: string;
  onFilesSelected: (files: File[]) => void;
}

const MAX_FILE_SIZE = FILE_VALIDATION.MAX_FILE_SIZE_BYTES;

/**
 * Helper function to convert File to Base64 string
 */
function fileToBase64(file: File): Promise<string> {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.onload = () => {
      const result = reader.result as string;
      const base64 = result.split(",")[1];
      if (!base64) {
        reject(new Error("Failed to convert file to Base64"));
        return;
      }
      resolve(base64);
    };
    reader.onerror = reject;
    reader.readAsDataURL(file);
  });
}

export function FileUploadZone({ caseId, onFilesSelected }: FileUploadProps) {
  const [selectedFiles, setSelectedFiles] = useState<File[]>([]);
  const [isProcessing, setIsProcessing] = useState(false);
  const [fileErrors, setFileErrors] = useState<string[]>([]);
  const fileInputRef = useRef<HTMLInputElement>(null);

  // Story 3.2: Backend validation
  const validateFileMutation = api.file.validateFileFormat.useMutation();

  // Story 3.3: File upload mutation
  const uploadFileMutation = api.file.uploadFile.useMutation({
    onSuccess: (data) => {
      toast.success(`${data.document.originalFileName}: ${data.message}`);
      // Remove uploaded file from selection list
      setSelectedFiles((prev) =>
        prev.filter((f) => f.name !== data.document.originalFileName)
      );
    },
    onError: (err) => {
      toast.error(err.message || "íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨");
    },
  });

  const onDrop = useCallback(
    async (acceptedFiles: File[], rejectedFiles: FileRejection[]) => {
      setIsProcessing(true);

      // Handle file size rejections
      if (rejectedFiles.length > 0) {
        rejectedFiles.forEach((rejection) => {
          const errors = rejection.errors.map((err) => {
            if (err.code === "file-too-large") {
              return `íŒŒì¼ "${rejection.file.name}"ì´(ê°€) 50MB ì œí•œì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤`;
            }
            if (err.code === "file-invalid-type") {
              return `íŒŒì¼ "${rejection.file.name}"ì€(ëŠ”) ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì…ë‹ˆë‹¤`;
            }
            return `íŒŒì¼ "${rejection.file.name}" ì—…ë¡œë“œ ì‹¤íŒ¨`;
          });
          setFileErrors((prev) => [...prev, ...errors]);
          errors.forEach((err) => toast.error(err));
        });
      }

      // Backend validation + Upload (Story 3.2 + Story 3.3)
      const validFiles: File[] = [];

      for (const file of acceptedFiles) {
        try {
          // Story 3.2: Validate file format
          const fileBuffer = await fileToBase64(file);

          // Story 3.3: Upload validated file to S3
          const result = await uploadFileMutation.mutateAsync({
            caseId,
            fileName: file.name,
            fileType: file.type,
            fileSize: file.size,
            fileBuffer,
          });

          if (result.success) {
            validFiles.push(file);
          }
        } catch (error) {
          const errorMsg =
            error instanceof Error ? error.message : "íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨";
          setFileErrors((prev) => [...prev, `${file.name}: ${errorMsg}`]);
          toast.error(`${file.name}: ${errorMsg}`);
        }
      }

      // Check for duplicates
      const newFiles = validFiles.filter(
        (newFile) =>
          !selectedFiles.some(
            (existingFile) =>
              existingFile.name === newFile.name &&
              existingFile.size === newFile.size
          )
      );

      if (newFiles.length < validFiles.length) {
        const duplicateCount = validFiles.length - newFiles.length;
        const dupMsg = `${duplicateCount}ê°œì˜ ì¤‘ë³µ íŒŒì¼ì´ ê±´ë„ˆë›°ê¸°ë˜ì—ˆìŠµë‹ˆë‹¤`;
        setFileErrors((prev) => [...prev, dupMsg]);
        toast.info(dupMsg);
      }

      setSelectedFiles((prev) => [...prev, ...newFiles]);
      onFilesSelected(newFiles);

      // Clear errors after 5 seconds
      setTimeout(() => {
        setFileErrors([]);
      }, 5000);

      setIsProcessing(false);
    },
    [onFilesSelected, selectedFiles, uploadFileMutation, caseId]
  );

  // ... rest of the component (useDropzone config, UI rendering) ...
}
```

**5. Required Dependencies**

```bash
# AWS SDK v3
npm install @aws-sdk/client-s3

# Prisma schema update
npx prisma generate

# Database migration (after schema change)
npx prisma migrate dev --name add_document_model
```

**6. Environment Variables**

```bash
# .env
DATABASE_URL="postgresql://..."
AWS_ACCESS_KEY_ID="your-access-key"
AWS_SECRET_ACCESS_KEY="your-secret-key"
AWS_REGION="ap-northeast-2"
S3_BUCKET_NAME="pharos-bmad-files"
```

### Project Structure Notes

**File Locations:**
- **NEW:** `src/lib/s3.ts` - S3 upload/download utilities
- **NEW:** `prisma/schema.prisma` - Add Document model
- **MODIFY:** `src/server/api/routers/file.ts` - Add uploadFile mutation
- **MODIFY:** `src/components/upload-zone.tsx` - Integrate upload mutation

**Import Aliases:**
- `~/lib/s3` - S3 utilities
- `~/lib/file-validation` - Validation constants (Story 3.2)
- `~/utils/api` - tRPC utilities

**Naming Conventions:**
- Functions: camelCase with descriptive verbs (`uploadFileToS3`, `deleteFileFromS3`)
- S3 Keys: UUID prefix + original filename (`uuid-filename.xlsx`)
- Database tables: snake_case (`documents`)
- Prisma models: PascalCase (`Document`)

**Existing Patterns (from Story 3.2):**
- Base64 file transmission (already implemented)
- File validation logic (re-use from Story 3.2)
- Error handling with TRPCError
- Toast notifications for user feedback

### References

- **Epic 3 Stories:** `_bmad-output/planning-artifacts/epics.md` (lines 618-646)
- **Architecture:** `_bmad-output/planning-artifacts/architecture.md`
  - File upload: lines 511-523 (multipart/form-data + S3)
  - S3 configuration: lines 699-710 (AWS S3 ap-northeast-2)
  - Environment variables: lines 722-730 (AWS credentials)
  - Data flow: lines 1457-1458 (FileUploader â†’ tRPC â†’ S3 â†’ Prisma)
- **Previous Story:** `_bmad-output/implementation-artifacts/3-2-file-format-validation.md`
  - Base64 conversion logic (lines 446-457)
  - File validation patterns (lines 423-444)
  - Error handling approaches (lines 459-466)

### Dependencies

**Required Stories:**
- âœ… Epic 1: ì‚¬ìš©ì ì¸ì¦ (JWT ê¸°ë°˜, userId í•„ìˆ˜)
- âœ… Epic 2: íŒŒì‚° ì‚¬ê±´ ê´€ë¦¬ (Case ëª¨ë¸, caseId í•„ìˆ˜)
- âœ… Story 3.1: íŒŒì¼ ì—…ë¡œë“œ UI (FileUploadZone ì»´í¬ë„ŒíŠ¸)
- âœ… Story 3.2: íŒŒì¼ í˜•ì‹ ê²€ì¦ (Base64 ë³€í™˜, ê²€ì¦ ë¡œì§ ì¬ì‚¬ìš©)

**Next Stories (will use Document metadata):**
- Story 3.4: íŒŒì¼ êµ¬ì¡° ë¶„ì„ (Documentì—ì„œ S3 í‚¤ ì¡°íšŒ)
- Story 3.6: ë°ì´í„° ì¶”ì¶œ (S3ì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ íŒŒì‹±)
- Story 3.7: ì—…ë¡œë“œ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°/ì‚­ì œ (Document CRUD ì—°ì‚°)

### Testing Standards Summary

**Unit Tests:**
- `uploadFileToS3` helper function
  - Successful upload returns S3 key
  - Upload failure throws error
- `deleteFileFromS3` helper function
  - Successful deletion
  - Delete non-existent file handling
- `uploadFile` mutation
  - Validation failure (invalid file type, size exceeded)
  - Successful upload creates Document record
  - Rollback on DB create failure (S3 object deleted)

**Integration Tests:**
- File upload flow:
  1. File validation (Story 3.2)
  2. S3 upload
  3. Document creation
  4. Error handling at each step
- RBAC: Only case owner can upload files
- Rollback: DB create failure â†’ S3 object cleanup

**Manual Testing Checklist:**
- [ ] ì •ìƒ íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ (ì—‘ì…€, CSV, PDF)
- [ ] S3 ë²„í‚·ì— íŒŒì¼ ì €ì¥ í™•ì¸ (UUID íŒŒì¼ëª…)
- [ ] Document í…Œì´ë¸”ì— ë©”íƒ€ë°ì´í„° í™•ì¸
- [ ] ì›ë³¸ íŒŒì¼ëª… ë³´ì¡´ í™•ì¸
- [ ] íŒŒì¼ í¬ê¸° ì´ˆê³¼ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€
- [ ] ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ë¡¤ë°± í™•ì¸ (S3 ê°ì²´ ì‚­ì œ)
- [ ] ê¶Œí•œ ì—†ëŠ” ì‚¬ìš©ì ì—…ë¡œë“œ ì‹œë„ ì°¨ë‹¨ (RBAC)

---

## Implementation Tasks

- [ ] **Task 1: Add Document model to Prisma schema** (AC: 2)
  - [ ] 1.1: Add Document model to `prisma/schema.prisma`
  - [ ] 1.2: Define fields (id, caseId, originalFileName, s3Key, fileSize, mimeType, uploadedAt, uploaderId)
  - [ ] 1.3: Add relations (case, uploader)
  - [ ] 1.4: Add indexes (caseId, uploaderId)
  - [ ] 1.5: Run `npx prisma generate`
  - [ ] 1.6: Run `npx prisma migrate dev --name add_document_model`

- [ ] **Task 2: Create S3 utility functions** (AC: 1)
  - [ ] 2.1: Create `src/lib/s3.ts`
  - [ ] 2.2: Initialize S3Client with AWS credentials
  - [ ] 2.3: Implement `uploadFileToS3` function (UUID filename)
  - [ ] 2.4: Implement `deleteFileFromS3` function (for rollback)
  - [ ] 2.5: Add error handling and logging

- [ ] **Task 3: Implement uploadFile mutation** (AC: 1, 2, 3)
  - [ ] 3.1: Add `uploadFile` procedure to `src/server/api/routers/file.ts`
  - [ ] 3.2: Re-use file validation logic from Story 3.2
  - [ ] 3.3: Call S3 upload with UUID filename
  - [ ] 3.4: Create Document record in database
  - [ ] 3.5: Implement rollback on DB failure (delete S3 object)
  - [ ] 3.6: Add comprehensive error handling

- [ ] **Task 4: Integrate upload into FileUploadZone** (AC: 1, 2)
  - [ ] 4.1: Add `uploadFile` mutation to FileUploadZone
  - [ ] 4.2: Replace validateFileFormat with uploadFile call
  - [ ] 4.3: Show success toast with file metadata
  - [ ] 4.4: Show error toast for upload failures
  - [ ] 4.5: Remove uploaded file from selection list

- [ ] **Task 5: Install and configure dependencies** (AC: 1)
  - [ ] 5.1: Install `@aws-sdk/client-s3`
  - [ ] 5.2: Configure environment variables (.env)
  - [ ] 5.3: Set up AWS credentials
  - [ ] 5.4: Verify S3 bucket exists (ap-northeast-2)

- [ ] **Task 6: Add TypeScript types** (AC: 1, 2)
  - [ ] 6.1: Define S3 upload input schema
  - [ ] 6.2: Define upload response type
  - [ ] 6.3: Ensure proper type annotations for S3 operations

- [ ] **Task 7: Error handling and UX** (AC: 3, 4)
  - [ ] 7.1: Korean error messages for each failure scenario
  - [ ] 7.2: Network error handling with retry suggestion
  - [ ] 7.3: Rollback mechanism (S3 object cleanup)
  - [ ] 7.4: Toast notifications for upload progress

- [ ] **Task 8: Validation** (ì„ íƒì‚¬í•­)
  - [ ] 8.1: Run TypeScript check: `npm run typecheck`
  - [ ] 8.2: Run ESLint: `npm run lint`
  - [ ] 8.3: Manual browser testing with different file types
  - [ ] 8.4: Verify S3 bucket contains uploaded files
  - [ ] 8.5: Verify Document records in database

---

## ğŸ” Code Review Findings

**Review Date:** 2026-01-09
**Review Method:** BMAD Adversarial Code Review
**Reviewer:** Senior Developer Agent
**Status:** âš ï¸ **ACTION REQUIRED** - 7 issues found (1 CRITICAL, 3 MEDIUM, 3 LOW)

---

### ğŸš¨ CRITICAL Issues

#### **CRITICAL-1: í™˜ê²½ë³€ìˆ˜ ëˆ„ë½ ì‹œ ë¹ˆ ë¬¸ìì—´ ì‚¬ìš© - S3 ì¸ì¦ ì‹¤íŒ¨**

**Location:** [src/lib/s3.ts#L26-L30](src/lib/s3.ts#L26-L30)

**Severity:** CRITICAL
**AC Impact:** AC1 (S3 íŒŒì¼ ì—…ë¡œë“œ) - í™˜ê²½ë³€ìˆ˜ ëˆ„ë½ ì‹œ ì•”ì‹œì  ì‹¤íŒ¨

**Problem:**
```typescript
credentials: {
  accessKeyId: process.env.AWS_ACCESS_KEY_ID ?? "",
  secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY ?? "",
},
```

**Vulnerability Analysis:**
- **ë¹ˆ ë¬¸ìì—´ ì „ë‹¬:** í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìœ¼ë©´ `""` (ë¹ˆ ë¬¸ìì—´)ì´ AWSì— ì „ë‹¬ë¨
- **ì•”ì‹œì  ì‹¤íŒ¨:** S3 ìš”ì²­ ì‹œ AWS SDKê°€ ë¹ˆ ë¬¸ìì—´ë¡œ ì¸ì¦ ì‹œë„ â†’ íƒ€ì„ì•„ì›ƒê¹Œì§€ ê¸°ë‹¤ë¦¼
- **ì—ëŸ¬ ë©”ì‹œì§€ ë¶ˆëª…í™•:** "InvalidAccessKeyId" ëŒ€ì‹  "NetworkingError" ë“± ë‹¤ì–‘í•œ ì—ëŸ¬ í‘œì‹œ

**Impact:**
- **ê°œë°œ í™˜ê²½ ì„¤ì • ì˜¤ë¥˜ ë°œê²¬ ì§€ì—°:** í™˜ê²½ë³€ìˆ˜ ëˆ„ë½ì„ ì¦‰ì‹œ ê°ì§€í•˜ì§€ ëª»í•¨
- **ë””ë²„ê¹… ì–´ë ¤ì›€:** ì‹¤ì œ ì›ì¸(í™˜ê²½ë³€ìˆ˜)ê³¼ ë‹¤ë¥¸ ì—ëŸ¬ ë©”ì‹œì§€ë¡œ ì¸í•œ í˜¼ë™
- **ì„œë²„ë¦¬ìŠ¤ í™˜ê²½ ë¬¸ì œ:** Vercelì—ì„œ í™˜ê²½ë³€ìˆ˜ ì„¤ì • ëˆ„ë½ ì‹œ ë°°í¬ í›„ ì‹¤íŒ¨

**Recommended Fix:**
```typescript
// src/lib/s3.ts

// S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í•¨ìˆ˜ (í™˜ê²½ë³€ìˆ˜ ê²€ì¦ í¬í•¨)
function initializeS3Client(): S3Client {
  const region = process.env.AWS_REGION ?? "ap-northeast-2";
  const accessKeyId = process.env.AWS_ACCESS_KEY_ID;
  const secretAccessKey = process.env.AWS_SECRET_ACCESS_KEY;
  const bucketName = process.env.S3_BUCKET_NAME;

  // í™˜ê²½ë³€ìˆ˜ ê²€ì¦ (ê°œë°œ/í”„ë¡œë•ì…˜ ëª¨ë‘)
  if (!accessKeyId || !secretAccessKey) {
    throw new Error(
      "S3 í™˜ê²½ë³€ìˆ˜ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤"
    );
  }

  // ê°œë°œ í™˜ê²½ì—ì„œë§Œ bucketName ê²€ì¦ (í…ŒìŠ¤íŠ¸ìš© ëª¨í‚¹ í—ˆìš©)
  if (process.env.NODE_ENV === "production" && !bucketName) {
    throw new Error("S3_BUCKET_NAME í™˜ê²½ë³€ìˆ˜ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤");
  }

  return new S3Client({
    region,
    credentials: { accessKeyId, secretAccessKey },
  });
}

// ëª¨ë“ˆ ë¡œë“œ ì‹œ ì´ˆê¸°í™” (ì¦‰ì‹œ ì‹¤íŒ¨ë¡œ ë¹ ë¥¸ ê°ì§€)
const s3Client = initializeS3Client();

export const S3_BUCKET = process.env.S3_BUCKET_NAME ?? "pharos-bmad-files";

// í…ŒìŠ¤íŠ¸ìš© ëª¨í‚¹ í—¬í¼
export function __TEST__overrideS3Client(mockClient: S3Client) {
  if (process.env.NODE_ENV === "test") {
    (globalThis as any).__S3_CLIENT_OVERRIDE__ = mockClient;
  }
}

function getS3Client(): S3Client {
  return (globalThis as any).__S3_CLIENT_OVERRIDE__ ?? s3Client;
}
```

---

### âš ï¸ MEDIUM Issues

#### **MEDIUM-1: RBAC ëˆ„ë½ - Case ì ‘ê·¼ ê¶Œí•œ ê²€ì¦ ì—†ìŒ**

**Location:** [src/server/api/routers/file.ts#L379](src/server/api/routers/file.ts#L379)

**Severity:** MEDIUM
**AC Impact:** AC4 (íŒŒì¼ ì ‘ê·¼ ì œì–´) - ê¶Œí•œ ìš°íšŒ ê°€ëŠ¥

**Problem:**
```typescript
uploadFile: protectedProcedure
  .input(z.object({
    caseId: z.string().min(1, "ì‚¬ê±´ IDëŠ” í•„ìˆ˜ í•­ëª©ì…ë‹ˆë‹¤"),
    // ...
  }))
  .mutation(async ({ ctx, input }) => {
    const { caseId, /* ... */ } = input;
    const userId = ctx.userId;

    // âŒ Case ì ‘ê·¼ ê¶Œí•œ ê²€ì¦ ì—†ìŒ
    // ëˆ„êµ¬ë‚˜ ëª¨ë“  Caseì— íŒŒì¼ ì—…ë¡œë“œ ê°€ëŠ¥
```

**Vulnerability:**
- **ê¶Œí•œ ìš°íšŒ:** ë¡œê·¸ì¸ëœ ì‚¬ìš©ìê°€ ëª¨ë“  Caseì— íŒŒì¼ ì—…ë¡œë“œ ê°€ëŠ¥
- **ë°ì´í„° ì˜¤ì—¼:** ì˜ë„ì¹˜ ì•Šì€ Caseì— íŒŒì¼ì´ ì—…ë¡œë“œë  ìˆ˜ ìˆìŒ
- **ë³´ì•ˆ ìœ„ë°˜:** ì‚¬ìš©ìAê°€ ì‚¬ìš©ìBì˜ ì‚¬ê±´ì— íŒŒì¼ ì—…ë¡œë“œ ê°€ëŠ¥

**Attack Scenario:**
```javascript
// ì‚¬ìš©ìAê°€ ì‚¬ìš©ìBì˜ ì‚¬ê±´ì— íŒŒì¼ ì—…ë¡œë“œ ì‹œë„
await uploadFileMutation.mutateAsync({
  caseId: "user-b-case-id", // ë‹¤ë¥¸ ì‚¬ìš©ìì˜ Case
  fileName: "malicious.pdf",
  // ...
});
// â†’ ì„±ê³µ! ì‚¬ìš©ìBì˜ ì‚¬ê±´ì— ì‚¬ìš©ìAì˜ íŒŒì¼ì´ ì €ì¥ë¨
```

**Recommended Fix:**
```typescript
uploadFile: protectedProcedure
  .input(z.object({
    caseId: z.string().min(1, "ì‚¬ê±´ IDëŠ” í•„ìˆ˜ í•­ëª©ì…ë‹ˆë‹¤"),
    // ...
  }))
  .mutation(async ({ ctx, input }) => {
    const { caseId, /* ... */ } = input;
    const userId = ctx.userId;

    // âœ… RBAC: Case ì ‘ê·¼ ê¶Œí•œ ê²€ì¦
    const targetCase = await ctx.db.case.findUnique({
      where: { id: caseId },
      select: { lawyerId: true },
    });

    if (!targetCase) {
      throw new TRPCError({
        code: "NOT_FOUND",
        message: "ì‚¬ê±´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
      });
    }

    // âœ… Case ë‹´ë‹¹ì ë˜ëŠ” Adminë§Œ ì—…ë¡œë“œ ê°€ëŠ¥
    if (targetCase.lawyerId !== userId && ctx.userRole !== "ADMIN") {
      throw new TRPCError({
        code: "FORBIDDEN",
        message: "ì´ ì‚¬ê±´ì— íŒŒì¼ì„ ì—…ë¡œë“œí•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤",
      });
    }

    // íŒŒì¼ ì—…ë¡œë“œ ë¡œì§ ê³„ì†...
```

---

#### **MEDIUM-2: ì¤‘ë³µ íŒŒì¼ ì—…ë¡œë“œ ê°ì§€ ì—†ìŒ**

**Location:** [src/server/api/routers/file.ts#L379-L460](src/server/api/routers/file.ts#L379-L460)

**Severity:** MEDIUM
**AC Impact:** AC2 (Document ë©”íƒ€ë°ì´í„° ìƒì„±) - ì¤‘ë³µ ì €ì¥

**Problem:**
```typescript
uploadFile: protectedProcedure
  .mutation(async ({ ctx, input }) => {
    // íŒŒì¼ ê²€ì¦, S3 ì—…ë¡œë“œ, DB ìƒì„±
    // âŒ ë™ì¼í•œ íŒŒì¼ì„ ì—¬ëŸ¬ ë²ˆ ì—…ë¡œë“œí•˜ëŠ”ì§€ í™•ì¸í•˜ì§€ ì•ŠìŒ

    const document = await ctx.db.document.create({
      data: {
        caseId,
        originalFileName: fileName, // ë™ì¼í•œ íŒŒì¼ëª… í—ˆìš©
        s3Key, // UUIDë¼ ì¤‘ë³µë˜ì§€ ì•ŠìŒ
        // ...
      },
    });
```

**Impact:**
- **ìŠ¤í† ë¦¬ì§€ ë‚­ë¹„:** ë™ì¼í•œ íŒŒì¼ì´ ì—¬ëŸ¬ ë²ˆ S3ì— ì—…ë¡œë“œë¨
- **ë¹„ìš© ì¦ê°€:** S3 ì €ì¥ ë¹„ìš©, ì „ì†¡ ë¹„ìš© ë°œìƒ
- **ì‚¬ìš©ì ê²½í—˜ ì €í•˜:** ì‹¤ìˆ˜ë¡œ ê°™ì€ íŒŒì¼ ì—¬ëŸ¬ ë²ˆ ì—…ë¡œë“œ ê°€ëŠ¥

**Recommended Fix:**
```typescript
// âœ… ì¤‘ë³µ íŒŒì¼ ê°ì§€ ì˜µì…˜ (ì„ íƒì  íŒŒë¼ë¯¸í„°)
uploadFile: protectedProcedure
  .input(
    z.object({
      caseId: z.string().min(1, "ì‚¬ê±´ IDëŠ” í•„ìˆ˜ í•­ëª©ì…ë‹ˆë‹¤"),
      fileName: z.string().min(1, "íŒŒì¼ëª…ì€ í•„ìˆ˜ í•­ëª©ì…ë‹ˆë‹¤"),
      fileType: z.string().min(1, "íŒŒì¼ íƒ€ì…ì€ í•„ìˆ˜ í•­ëª©ì…ë‹ˆë‹¤"),
      fileSize: z.number().min(0, "íŒŒì¼ í¬ê¸°ëŠ” 0 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤"),
      fileBuffer: z.string().min(1, "íŒŒì¼ ë‚´ìš©ì€ í•„ìˆ˜ í•­ëª©ì…ë‹ˆë‹¤"),
      allowDuplicates: z.boolean().optional().default(false), // âœ… ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„°
    })
  )
  .mutation(async ({ ctx, input }) => {
    const { caseId, fileName, fileSize, allowDuplicates } = input;

    // âœ… ì¤‘ë³µ íŒŒì¼ ê°ì§€ (ê°™ì€ Case, ê°™ì€ íŒŒì¼ëª…, ê°™ì€ í¬ê¸°)
    if (!allowDuplicates) {
      const existingDoc = await ctx.db.document.findFirst({
        where: {
          caseId,
          originalFileName: fileName,
          fileSize,
          uploadedAt: {
            gte: new Date(Date.now() - 24 * 60 * 60 * 1000), // 24ì‹œê°„ ì´ë‚´
          },
        },
      });

      if (existingDoc) {
        throw new TRPCError({
          code: "CONFLICT",
          message: `"${fileName}" íŒŒì¼ì€ ì´ë¯¸ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤ (ë™ì¼í•œ í¬ê¸°: ${(fileSize / 1024 / 1024).toFixed(2)}MB). ì¤‘ë³µ ì—…ë¡œë“œë¥¼ ì›í•˜ì‹œë©´ allowDuplicatesë¥¼ trueë¡œ ì„¤ì •í•˜ì„¸ìš”`,
        });
      }
    }

    // íŒŒì¼ ì—…ë¡œë“œ ë¡œì§ ê³„ì†...
```

---

#### **MEDIUM-3: Rollback ì‹¤íŒ¨ ì‹œ S3 ê°ì²´ ê³ ì•„ ìƒíƒœ**

**Location:** [src/server/api/routers/file.ts#L445-L455](src/server/api/routers/file.ts#L445-L455)

**Severity:** MEDIUM
**AC Impact:** AC3 (ì—…ë¡œë“œ ì‹¤íŒ¨ ì²˜ë¦¬) - ë¡¤ë°± ë¶ˆì™„ì „

**Problem:**
```typescript
} catch (error) {
  console.error("[Document Create Error]", error);

  // Rollback: Delete S3 object if DB creation fails
  try {
    await deleteFileFromS3(s3Key);
    console.log("[Rollback Success] S3 object deleted after DB failure");
  } catch (deleteError) {
    // âŒ Rollback ì‹¤íŒ¨ ì‹œ S3 ê°ì²´ê°€ ì˜êµ¬ì ìœ¼ë¡œ ë‚¨ìŒ
    console.error("[Rollback Error] Failed to delete S3 object", deleteError);
  }

  throw new TRPCError({
    code: "INTERNAL_SERVER_ERROR",
    message: "íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨",
  });
}
```

**Vulnerability:**
- **ê³ ì•„ S3 ê°ì²´:** Rollback ì‹¤íŒ¨ ì‹œ S3ì— íŒŒì¼ì´ ì˜êµ¬ì ìœ¼ë¡œ ë‚¨ìŒ
- **ìŠ¤í† ë¦¬ì§€ ëˆ„ì¶œ:** ì¤‘ê°„ì— DB ì‹¤íŒ¨ ë°œìƒ ì‹œë§ˆë‹¤ S3 ê³µê°„ ë‚­ë¹„
- **ìˆ˜ë™ ì •ë¦¬ í•„ìš”:** ê´€ë¦¬ìê°€ ìˆ˜ë™ìœ¼ë¡œ ê³ ì•„ ê°ì²´ ì œê±°í•´ì•¼ í•¨

**Recommended Fix:**
```typescript
// âœ… Dead Letter Queue íŒ¨í„´ìœ¼ë¡œ ê³ ì•„ ê°ì²´ ì¶”ì 
// 1. Prisma ìŠ¤í‚¤ë§ˆì— OrphanedS3Object ëª¨ë¸ ì¶”ê°€
model OrphanedS3Object {
  id         String   @id @default(uuid())
  s3Key      String   @unique
  caseId     String
  fileName   String
  createdAt  DateTime @default(now())
  cleanedAt  DateTime?
  
  @@index([createdAt])
  @@map("orphaned_s3_objects")
}

// 2. Rollback ì‹¤íŒ¨ ì‹œ ê¸°ë¡
} catch (error) {
  console.error("[Document Create Error]", error);

  // Rollback ì‹œë„
  try {
    await deleteFileFromS3(s3Key);
    console.log("[Rollback Success] S3 object deleted");
  } catch (deleteError) {
    // âœ… Rollback ì‹¤íŒ¨ ì‹œ DBì— ê¸°ë¡ (ë‚˜ì¤‘ì— ì •ë¦¬ ì‘ì—… ê°€ëŠ¥)
    console.error("[Rollback Error] S3 object orphaned", deleteError);
    
    try {
      await ctx.db.orphanedS3Object.create({
        data: {
          s3Key,
          caseId,
          fileName,
        },
      });
      console.log("[Orphan Recorded] S3 object recorded for cleanup");
    } catch (recordError) {
      console.error("[Record Error] Failed to record orphaned object", recordError);
    }
  }

  throw new TRPCError({
    code: "INTERNAL_SERVER_ERROR",
    message: "íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨",
  });
}

// 3. ì •ë¦¬ ì‘ì—…ìš© Cron Job (ë³„ë„ ì‘ì—…)
// - ë§¤ì¼ OrphanedS3Object ì¡°íšŒ ë° S3 ì‚­ì œ ì‹œë„
// - 7ì¼ ì´ìƒ ëœ ê°ì²´ ì‚­ì œ
```

---

### ğŸ“ LOW Issues

#### **LOW-1: S3 í‚¤ í˜•ì‹ ê°œì„  í•„ìš”**

**Location:** [src/lib/s3.ts#L60](src/lib/s3.ts#L60)

**Severity:** LOW
**AC Impact:** AC1 (S3 íŒŒì¼ ì—…ë¡œë“œ) - ì¶”ì  ìš©ì´ì„±

**Problem:**
```typescript
const s3Key = `${randomUUID()}-${fileName}`;
```

**Potential Issues:**
- **UUID-íŒŒì¼ëª… í˜•ì‹:** `550e8400-e29b-41d4-a716-446655440000-statement.xlsx`
- **íŒŒì¼ëª…ì— í•˜ì´í”ˆ í¬í•¨:** `my-file-name.xlsx` â†’ `UUID-my-file-name.xlsx`
- **ì¶”ì  ì–´ë ¤ì›€:** S3 ì½˜ì†”ì—ì„œ íŒŒì¼ëª…ìœ¼ë¡œ ê²€ìƒ‰ ì‹œ UUID ì•ë¶€ë¶„ ë•Œë¬¸ì— ì–´ë ¤ì›€

**Recommended Improvement:**
```typescript
// âœ… ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¡œ ê°œì„ 
const s3Key = `cases/${caseId}/${Date.now()}-${randomUUID()}-${fileName}`;

// ê²°ê³¼: cases/123e4567-89ab/1704782400000-550e8400-statement.xlsx
// ì¥ì :
// 1. Caseë³„ë¡œ íŒŒì¼ ê·¸ë£¹í™” (ì ‘ê·¼ ì œì–´, ì •ë¦¬ ìš©ì´)
// 2. íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì—…ë¡œë“œ ìˆœì„œ íŒŒì•…
// 3. íŒŒì¼ëª… ì¶”ì  ìš©ì´ (UUID ì œì™¸í•˜ê³  ê²€ìƒ‰)

// ë˜ëŠ” íŒŒí‹°ì…˜ íŒ¨í„´
const s3Key = `${caseId.slice(0, 2)}/${caseId.slice(2, 4)}/${caseId}/${randomUUID()}-${fileName}`;
// ê²°ê³¼: 12/34/5678/550e8400-statement.xlsx
// ì¥ì : S3 íŒŒí‹°ì…˜ ë¶„ì‚°ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
```

---

#### **LOW-2: ì—…ë¡œë“œ ì§„í–‰ë¥  í‘œì‹œ ì—†ìŒ**

**Location:** [src/components/upload-zone.tsx#L95-L117](src/components/upload-zone.tsx#L95-L117)

**Severity:** LOW
**AC Impact:** UX í–¥ìƒ

**Problem:**
```typescript
for (const file of acceptedFiles) {
  try {
    const fileBuffer = await fileToBase64(file); // â³ ì‹œê°„ ì†Œìš”
    const result = await uploadFileMutation.mutateAsync({ /* ... */ }); // â³ ì‹œê°„ ì†Œìš”
    
    if (result.success) {
      successfullyUploadedFiles.push(file);
      toast.success(`${file.name}: ${result.message}`);
    }
  } catch (error) {
    // ...
  }
}
```

**Improvement Needed:**
- **ì§„í–‰ë¥  ë¶ˆëª…í™•:** ëŒ€ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ ì‹œ ì§„í–‰ ìƒí™©ì„ ì•Œ ìˆ˜ ì—†ìŒ
- **ìˆœì°¨ ì²˜ë¦¬:** íŒŒì¼ì„ ìˆœì„œëŒ€ë¡œ í•˜ë‚˜ì”© ì—…ë¡œë“œ (ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥)
- **ì·¨ì†Œ ë¶ˆê°€:** ì—…ë¡œë“œ ì¤‘ê°„ì— ì·¨ì†Œí•  ìˆ˜ ì—†ìŒ

**Recommended Improvement:**
```typescript
// âœ… ì§„í–‰ë¥  ìƒíƒœ ì¶”ê°€
const [uploadProgress, setUploadProgress] = useState<{
  [fileName: string]: { stage: string; progress: number };
}>({});

// ê° íŒŒì¼ë³„ ì§„í–‰ë¥  ì¶”ì 
for (const file of acceptedFiles) {
  try {
    setUploadProgress((prev) => ({
      ...prev,
      [file.name]: { stage: "ë³€í™˜ ì¤‘", progress: 10 },
    }));

    const fileBuffer = await fileToBase64(file);

    setUploadProgress((prev) => ({
      ...prev,
      [file.name]: { stage: "ê²€ì¦ ì¤‘", progress: 30 },
    }));

    const result = await uploadFileMutation.mutateAsync({
      // ...
    });

    setUploadProgress((prev) => ({
      ...prev,
      [file.name]: { stage: "ì™„ë£Œ", progress: 100 },
    }));

    if (result.success) {
      successfullyUploadedFiles.push(file);
      toast.success(`${file.name}: ${result.message}`);
    }
  } catch (error) {
    setUploadProgress((prev) => ({
      ...prev,
      [file.name]: { stage: "ì‹¤íŒ¨", progress: 0 },
    }));
  }
}

// UIì—ì„œ ì§„í–‰ë¥  í‘œì‹œ
{Object.entries(uploadProgress).map(([fileName, { stage, progress }]) => (
  <div key={fileName} className="flex items-center gap-2">
    <span>{fileName}</span>
    <span>{stage}</span>
    <div className="w-full bg-gray-200 rounded-full h-2">
      <div className="bg-blue-600 h-2 rounded-full" style={{ width: `${progress}%` }} />
    </div>
  </div>
))}
```

---

#### **LOW-3: ì—ëŸ¬ ë¡œê¹… ì¼ê´€ì„± ë¶€ì¡±**

**Location:** Various locations in s3.ts and file.ts

**Severity:** LOW
**AC Impact:** ìš´ì˜/ë””ë²„ê¹… ìš©ì´ì„±

**Problem:**
```typescript
// s3.ts
console.log(`[S3 Upload Success] File uploaded: ${s3Key}`);
console.error("[S3 Upload Error]", error);

// file.ts
console.error("[Document Create Error]", error);
console.error("[Rollback Error] Failed to delete S3 object", deleteError);
```

**Improvement Needed:**
- **ë¡œê¹… ìˆ˜ì¤€ ë¶ˆì¼ì¹˜:** ì„±ê³µ ë¡œê·¸ëŠ” `console.log`, ì—ëŸ¬ëŠ” `console.error`
- **êµ¬ì¡°í™”ëœ ë¡œê¹… ë¶€ì¡±:** JSON í˜•ì‹ì˜ êµ¬ì¡°í™”ëœ ë¡œê¹… ë¯¸ì‚¬ìš©
- **í”„ë¡œë•ì…˜ í™˜ê²½ ê³ ë ¤:** ë¡œê·¸ ì§‘ê³„ ì„œë¹„ìŠ¤(Sentry, DataDog) ì—°ë™ ê³ ë ¤

**Recommended Improvement:**
```typescript
// âœ… êµ¬ì¡°í™”ëœ ë¡œê±° ìƒì„± (src/lib/logger.ts)
type LogLevel = "info" | "warn" | "error";

interface LogContext {
  [key: string]: unknown;
}

class Logger {
  private context: string;

  constructor(context: string) {
    this.context = context;
  }

  private log(level: LogLevel, message: string, meta?: LogContext) {
    const logEntry = {
      timestamp: new Date().toISOString(),
      level,
      context: this.context,
      message,
      ...meta,
    };

    // ê°œë°œ: console, í”„ë¡œë•ì…˜: ë¡œê·¸ ì„œë¹„ìŠ¤
    if (process.env.NODE_ENV === "production") {
      // Sentry, DataDog ë“±ìœ¼ë¡œ ì „ì†¡
      // sendToLogService(logEntry);
    } else {
      if (level === "error") {
        console.error(JSON.stringify(logEntry));
      } else if (level === "warn") {
        console.warn(JSON.stringify(logEntry));
      } else {
        console.log(JSON.stringify(logEntry));
      }
    }
  }

  info(message: string, meta?: LogContext) {
    this.log("info", message, meta);
  }

  error(message: string, meta?: LogContext) {
    this.log("error", message, meta);
  }
}

// ì‚¬ìš©
const logger = new Logger("S3");
logger.info("File uploaded", { s3Key, fileName, fileSize });
logger.error("Upload failed", { s3Key, error: error.message });
```

---

## ğŸ“Š Review Summary

| ì‹¬ê°ë„ | Issue | AC Impact | Location |
|--------|-------|-----------|----------|
| **CRITICAL** | í™˜ê²½ë³€ìˆ˜ ëˆ„ë½ ì‹œ ë¹ˆ ë¬¸ìì—´ ì‚¬ìš© | AC1 | [s3.ts#L26](src/lib/s3.ts#L26) |
| **MEDIUM-1** | RBAC ëˆ„ë½ (Case ì ‘ê·¼ ê¶Œí•œ) | AC4 | [file.ts#L379](src/server/api/routers/file.ts#L379) |
| **MEDIUM-2** | ì¤‘ë³µ íŒŒì¼ ì—…ë¡œë“œ ê°ì§€ ì—†ìŒ | AC2 | [file.ts#L379](src/server/api/routers/file.ts#L379) |
| **MEDIUM-3** | Rollback ì‹¤íŒ¨ ì‹œ ê³ ì•„ ìƒíƒœ | AC3 | [file.ts#L445](src/server/api/routers/file.ts#L445) |
| **LOW-1** | S3 í‚¤ í˜•ì‹ ê°œì„  í•„ìš” | AC1 | [s3.ts#L60](src/lib/s3.ts#L60) |
| **LOW-2** | ì—…ë¡œë“œ ì§„í–‰ë¥  í‘œì‹œ ì—†ìŒ | UX | [upload-zone.tsx#L95](src/components/upload-zone.tsx#L95) |
| **LOW-3** | ì—ëŸ¬ ë¡œê¹… ì¼ê´€ì„± ë¶€ì¡± | ìš´ì˜ | Multiple locations |

**ì´ 7ê°œ Issue ë°œê²¬ (1 CRITICAL, 3 MEDIUM, 3 LOW)**

---

## âœ… Action Items

### Priority 1 (CRITICAL - Must Fix Before Release)

- [ ] **ACTION-1:** [s3.ts#L26](src/lib/s3.ts#L26) - í™˜ê²½ë³€ìˆ˜ ëˆ„ë½ ì‹œ ì¦‰ì‹œ ì‹¤íŒ¨í•˜ë„ë¡ ì´ˆê¸°í™” í•¨ìˆ˜ ì¶”ê°€ ë° ê²€ì¦ ë¡œì§ êµ¬í˜„

### Priority 2 (MEDIUM - Should Fix Soon)

- [ ] **ACTION-2:** [file.ts#L379](src/server/api/routers/file.ts#L379) - RBAC: Case ì ‘ê·¼ ê¶Œí•œ ê²€ì¦ ì¶”ê°€ (lawyerId ë˜ëŠ” ADMIN í™•ì¸)
- [ ] **ACTION-3:** [file.ts#L379](src/server/api/routers/file.ts#L379) - ì¤‘ë³µ íŒŒì¼ ì—…ë¡œë“œ ê°ì§€ ë¡œì§ ì¶”ê°€ (24ì‹œê°„ ì´ë‚´ ë™ì¼ íŒŒì¼ëª…+í¬ê¸°)
- [ ] **ACTION-4:** [file.ts#L445](src/server/api/routers/file.ts#L445) - Rollback ì‹¤íŒ¨ ì‹œ OrphanedS3Object í…Œì´ë¸”ì— ê¸°ë¡í•˜ëŠ” Dead Letter Queue íŒ¨í„´ êµ¬í˜„

### Priority 3 (LOW - Nice to Have)

- [ ] **ACTION-5:** [s3.ts#L60](src/lib/s3.ts#L60) - S3 í‚¤ í˜•ì‹ì„ `cases/${caseId}/${timestamp}-${uuid}-${filename}`ë¡œ ê°œì„ 
- [ ] **ACTION-6:** [upload-zone.tsx#L95](src/components/upload-zone.tsx#L95) - ì—…ë¡œë“œ ì§„í–‰ë¥  í‘œì‹œ UI ì¶”ê°€ (ë³€í™˜/ê²€ì¦/ì—…ë¡œë“œ ë‹¨ê³„ë³„ progress)
- [ ] **ACTION-7:** [s3.ts, file.ts] - êµ¬ì¡°í™”ëœ ë¡œê±° (src/lib/logger.ts) ë„ì…ìœ¼ë¡œ ë¡œê¹… ì¼ê´€ì„± í™•ë³´

---

**Story Status ë³€ê²½:** `ready-for-dev` â†’ `in-progress` (CRITICAL ë° MEDIUM issues ìˆ˜ì • í•„ìš”)

**ë‹¤ìŒ ë‹¨ê³„:**
1. CRITICAL issue ìˆ˜ì • (ACTION-1)
2. MEDIUM issues ìˆ˜ì • (ACTION-2, ACTION-3, ACTION-4)
3. ì „ì²´ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰
4. ì¬ì‹¬ì˜ ìš”ì²­

---

## Dev Agent Record

### Agent Model Used

_Claude Sonnet 4.5 (claude-sonnet-4-5-20250929) will implement this story_

### Completion Notes List

_Story completion notes will be added after implementation_

### File List

_Files created/modified during implementation will be listed here_
